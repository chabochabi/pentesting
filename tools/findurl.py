#!/usr/bin/python

import sys
import requests
import re
import argparse

parser = argparse.ArgumentParser(description="find all URLs in a URL o_O")
parser.add_argument('-u', '--url')
parser.add_argument('-f', '--file')
args = parser.parse_args()

if args.url == None and args.file == None:
	print("\n[*] Please provide an url or a file\n")
	parser.print_help()
	sys.exit()

def findurls(text):
	p = re.compile("(http|ftp|https|memcache|gopher):\/\/([\w_-]+(?:(?:\.[\w_-]+)+))([\w.,@?^=%&:/~+#-]*[\w@?^=%&/~+#-])?")
	
	matches = p.findall(text)
	urls = list()
	for groups in matches:
		url = "%s://%s%s" % (groups[0], groups[1], groups[2])
		if url not in urls:
			urls.append(url)
	
	print("[*] found %d URLs in %s\n" % (len(urls), args.url))
	for url in urls:
		print(url)
	
if args.url != None:
	req = requests.get(args.url, verify=False)	
	text = req.text.replace("\\/", "/")
elif args.file != None:
	fd = open(args.file, "r")
	text = fd.read()

findurls(text)
